{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Sample labeled data\n",
        "sentences = [\n",
        "    \"I like to play soccer\",\n",
        "    \"She sings beautifully\",\n",
        "    \"He runs every morning\",\n",
        "    \"They read books in the library\",\n",
        "    \"The cat sleeps on the windowsill\",\n",
        "    \"We eat dinner together\",\n",
        "    \"The flowers bloom in spring\",\n",
        "    \"She paints colorful pictures\",\n",
        "    \"He writes poems\",\n",
        "    \"The dog barks loudly\",\n",
        "    \"Birds chirp in the trees\",\n",
        "    \"The river flows peacefully\",\n",
        "    \"The sun sets in the evening\",\n",
        "    \"Stars twinkle in the night sky\",\n",
        "    \"Children play in the park\",\n",
        "    \"The wind rustles the leaves\",\n",
        "    \"The rain falls gently\",\n",
        "    \"The ocean waves crash\",\n",
        "    \"People walk on the sidewalk\",\n",
        "    \"The fire crackles and burns\",\n",
        "    \"The clock ticks\",\n",
        "    \"The train rumbles by\",\n",
        "    \"The car honks its horn\",\n",
        "    \"The baby giggles\",\n",
        "    \"The teacher explains the lesson\",\n",
        "    \"The student asks a question\",\n",
        "    \"The doctor examines the patient\",\n",
        "    \"The chef prepares the meal\",\n",
        "    \"The gardener waters the plants\",\n",
        "    \"The mechanic fixes the car\",\n",
        "    \"The dancer performs on stage\",\n",
        "    \"The actor delivers lines\",\n",
        "    \"The musician plays the guitar\",\n",
        "    \"The artist sketches a portrait\",\n",
        "    \"The scientist conducts experiments\",\n",
        "    \"The programmer writes code\",\n",
        "    \"The writer creates stories\",\n",
        "    \"The photographer captures moments\",\n",
        "    \"The journalist reports the news\",\n",
        "    \"The detective solves the case\",\n",
        "    \"The firefighter extinguishes the flames\",\n",
        "    \"The police officer patrols the streets\",\n",
        "    \"The astronaut floats in space\",\n",
        "    \"The farmer tends to the crops\",\n",
        "    \"The baker kneads the dough\",\n",
        "    \"The waiter serves the food\",\n",
        "    \"The cashier handles transactions\",\n",
        "    \"The lifeguard watches the pool\",\n",
        "    \"The lifeguard watches the pool\",\n",
        "    \"The lifeguard watches the pool\",\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    \"PRON VERB PART VERB NOUN\",\n",
        "    \"PRON VERB ADV\",\n",
        "    \"PRON VERB DET NOUN\",\n",
        "    \"PRON VERB NOUN ADP DET NOUN\",\n",
        "    \"DET NOUN VERB ADP DET NOUN\",\n",
        "    \"PRON VERB NOUN ADV\",\n",
        "    \"DET NOUN VERB ADP NOUN\",\n",
        "    \"PRON VERB ADJ NOUN\",\n",
        "    \"PRON VERB NOUN\",\n",
        "    \"DET NOUN VERB ADV\",\n",
        "    \"NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB ADV\",\n",
        "    \"DET NOUN VERB ADP DET NOUN\",\n",
        "    \"NOUN VERB ADP DET NOUN NOUN\",\n",
        "    \"NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB ADV\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB NOUN CONJ VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB ADV\",\n",
        "    \"DET NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB NOUN\",\n",
        "    \"DET NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB ADP NOUN\",\n",
        "    \"DET NOUN VERB ADP NOUN\",\n",
        "    \"DET NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB NOUN\",\n",
        "    \"DET NOUN VERB NOUN\",\n",
        "    \"DET NOUN VERB ADP DET NOUN\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB NOUN\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB ADP NOUN\",\n",
        "    \"DET NOUN VERB NOUN\",\n",
        "    \"DET NOUN VERB NOUN\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\",\n",
        "    \"DET NOUN VERB\"\n",
        "]\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert sentences to sequences of word indices\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Pad sequences for uniform input size\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Create label dictionary\n",
        "label_dict = {}\n",
        "for idx, label_seq in enumerate(labels):\n",
        "    label_dict[idx] = label_seq.split()\n",
        "\n",
        "# Convert label sequences to one-hot encoded vectors\n",
        "num_labels = max(len(label_dict[idx]) for idx in label_dict)\n",
        "label_vectors = np.zeros((len(label_dict), max_sequence_length, num_labels), dtype='float32')\n",
        "for idx, label_seq in label_dict.items():\n",
        "    for word_idx, label in enumerate(label_seq):\n",
        "        label_vectors[idx, word_idx, label_dict[idx].index(label)] = 1\n",
        "\n",
        "# Build and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=max_sequence_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(padded_sequences, label_vectors, epochs=100, verbose=1)\n",
        "\n",
        "# Example inference\n",
        "test_sentence = \"They will swim in the pool\"\n",
        "test_sequence = tokenizer.texts_to_sequences([test_sentence])\n",
        "padded_test_sequence = pad_sequences(test_sequence, maxlen=max_sequence_length, padding='post')\n",
        "predicted_labels = model.predict(padded_test_sequence)[0]\n",
        "\n",
        "# Convert predicted label probabilities to actual labels\n",
        "predicted_label_seq = [label_dict[0][np.argmax(label_probs)] for label_probs in predicted_labels]\n",
        "print(predicted_label_seq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ4_ilARYUwj",
        "outputId": "e2234619-23e6-46c8-aeb0-9a4bc87329c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 13ms/step - loss: 1.2659 - accuracy: 0.1333\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.2608 - accuracy: 0.2467\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.2560 - accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2507 - accuracy: 0.2467\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2451 - accuracy: 0.2467\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.2389 - accuracy: 0.2433\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2317 - accuracy: 0.2367\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2239 - accuracy: 0.2333\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2151 - accuracy: 0.2333\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2045 - accuracy: 0.2333\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1932 - accuracy: 0.2333\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1806 - accuracy: 0.2333\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1663 - accuracy: 0.2333\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1518 - accuracy: 0.2333\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1376 - accuracy: 0.2333\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1250 - accuracy: 0.2333\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1140 - accuracy: 0.2333\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1055 - accuracy: 0.2333\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0969 - accuracy: 0.2333\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0878 - accuracy: 0.2333\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0804 - accuracy: 0.2333\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.0725 - accuracy: 0.2533\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.0631 - accuracy: 0.3267\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0509 - accuracy: 0.3767\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0368 - accuracy: 0.4100\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0211 - accuracy: 0.3667\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0044 - accuracy: 0.2600\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9865 - accuracy: 0.2333\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9686 - accuracy: 0.2333\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9508 - accuracy: 0.2333\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9338 - accuracy: 0.2367\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9166 - accuracy: 0.2467\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9000 - accuracy: 0.2933\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8840 - accuracy: 0.3700\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8683 - accuracy: 0.3933\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8527 - accuracy: 0.3967\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8372 - accuracy: 0.3967\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8219 - accuracy: 0.3967\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8069 - accuracy: 0.3967\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7921 - accuracy: 0.3967\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7776 - accuracy: 0.3967\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7641 - accuracy: 0.3967\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7515 - accuracy: 0.4000\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7388 - accuracy: 0.4000\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7263 - accuracy: 0.4000\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7140 - accuracy: 0.4033\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7006 - accuracy: 0.4067\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6866 - accuracy: 0.5500\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6729 - accuracy: 0.5533\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6600 - accuracy: 0.5633\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6471 - accuracy: 0.5633\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6346 - accuracy: 0.5633\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6232 - accuracy: 0.5633\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6128 - accuracy: 0.5633\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6012 - accuracy: 0.5633\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5891 - accuracy: 0.5633\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5786 - accuracy: 0.5633\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5687 - accuracy: 0.5633\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5590 - accuracy: 0.5700\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5486 - accuracy: 0.5800\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5380 - accuracy: 0.5900\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5255 - accuracy: 0.5967\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5132 - accuracy: 0.6000\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5019 - accuracy: 0.6200\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4919 - accuracy: 0.6267\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4836 - accuracy: 0.6333\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4747 - accuracy: 0.6333\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4655 - accuracy: 0.6333\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4544 - accuracy: 0.6333\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4434 - accuracy: 0.6367\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4346 - accuracy: 0.6400\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4269 - accuracy: 0.6433\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4208 - accuracy: 0.6467\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4140 - accuracy: 0.6467\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4053 - accuracy: 0.6467\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3968 - accuracy: 0.6467\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3895 - accuracy: 0.6433\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3842 - accuracy: 0.6467\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3804 - accuracy: 0.6467\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3749 - accuracy: 0.6467\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3681 - accuracy: 0.6467\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3612 - accuracy: 0.6467\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3558 - accuracy: 0.6467\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3517 - accuracy: 0.6467\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3479 - accuracy: 0.6467\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3433 - accuracy: 0.6467\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3376 - accuracy: 0.6467\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3330 - accuracy: 0.6467\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3293 - accuracy: 0.6467\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3263 - accuracy: 0.6467\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3228 - accuracy: 0.6467\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3184 - accuracy: 0.6467\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3142 - accuracy: 0.6467\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3104 - accuracy: 0.6467\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3067 - accuracy: 0.6467\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3039 - accuracy: 0.6467\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3020 - accuracy: 0.6467\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2989 - accuracy: 0.6467\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2955 - accuracy: 0.6467\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2914 - accuracy: 0.6467\n",
            "1/1 [==============================] - 1s 706ms/step\n",
            "['PRON', 'PART', 'PRON', 'VERB', 'VERB', 'VERB']\n"
          ]
        }
      ]
    }
  ]
}